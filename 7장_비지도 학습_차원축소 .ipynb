{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a9a40e4",
   "metadata": {},
   "source": [
    "## 차원축소 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d105d534",
   "metadata": {},
   "source": [
    "차원축소는 정보 손실을 최소화하면서 원래 특성에서 가장 중요한 것을 포착하는 변수의 더 작은 셋을 찾는 방법으로 데이터를 압축한다. 차원 축소는 높은 차원과 관련된 문제를 완화하는데 도움이 되며, 탐색하기 어려운 고차원 데이터의 주요 특성을 시각화 할 수 있다. \n",
    "\n",
    "차원축소는 더 적은 특성을 사용해 데이터셋의 정보를 더 효율적으로 나타낸다. 이러한 기술은 정보가 없는 데이터의 변동을 무시하거나 데이터가 있는 저차원의 부분공간을 식별함으로써 데이터를 저차원 공간에 투영한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff82899",
   "metadata": {},
   "source": [
    "## 주성분 분석(PCA)\n",
    "\n",
    "분산을 가능한 높게 유지하면서 변수가 많은 데이터셋의 차원을 줄이는 것이다. PCA를 사용하면 원래 데이터 포인트의 대부분을 설명할 수 있는 데이터의 다른 표현이 있는지 여부를 이해할 수 있다.\n",
    "\n",
    "PCA는 선형 조합을 통해 원래 변수를 산출하는 새로운 변수셋을 찾는다. 새로운 변수를 주성분이라고 한다. 이러한 주성분을 직교(또는 독립적)하며 원본 데이터를 나타낸다. 구성요소의 수는 PCA 알고리즘의 하이퍼파라미터로 목표차원을 설정한다.  \n",
    "\n",
    "PCA 알고리즘은 원래 데이터를 주성분 공간에 투영함으로써 작동한다. 그런 다음 데이터의 최대 분산방향과 일치하는 주성분 순서를 식별한다. (이전에 계산된 성분이 포착한 변동을 고려한 후) 각 주성분은 데이터의 최대 분산 방향에 맞춰진다. \n",
    "\n",
    "순차 최적화는 또한 새 성분이 기존 성분과 상호 연관되지 않도록 한다. 따라서 결과 집합은 벡터공간에서 직교성을 갖는다. \n",
    "\n",
    "각 주성분이 설명하는 원본 데이터 분산량의 감소는 원본 특성 간의 상관관계 정도를 반영한다. 예를 들어 전체 특성 수에 비해 원래 변동의 95%를 포착하는 성분의 수는 원래 데이터의 선형적 독립성을 반영한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0692b5e",
   "metadata": {},
   "source": [
    "## 고유분해 \n",
    "\n",
    "1. 특성에 대한 공분산 행렬을 생성\n",
    "2. 공분산 행렬을 계산한 다음 공분산 행렬의 고유벡터를 계산한다. 이것이 최대 분산 방향이다.\n",
    "3. 고윳값을 생성한다. 이는 주성분의 크기를 정의한다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d60ca7",
   "metadata": {},
   "source": [
    "## 특이값 분해 (SVD)\n",
    "\n",
    "특이값 분해는 행렬을 세 개의 행렬로 분해하는 것으로 보다 일반적인 m x n 직사각형 행렬에 적용할 수 있다. SVD는 회소행렬(0이 아닌 요소가 거의 없는 행렬)을 처리할 수 있으므로 고유분해보다 더 효율적일 수 있다. 또한 SVD는 특히 일부 특성이 강한 상관관계를 가질 때 더 좋은 수치 안정성을 산출한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17acf616",
   "metadata": {},
   "source": [
    "## 커널 주성분 분석 (KPCA)\n",
    "\n",
    "PCA의 주요 한계는 선형변환만 가능하다는 것이다. KPCA는 PCA를 확장하여 비선형성을 처리한다. 먼저 원본 데이터를 일부 비선형 특성 공간에 매핑한다. 그런 다음 PCA를 적용해 해당 공간에서 주성분을 추출한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e26b01",
   "metadata": {},
   "source": [
    "## t-분산 확률적 이웃 임베딩(t-SNE)\n",
    "\n",
    "t-SNE는 각 포인트 주변의 이웃 확률 분포를 모델링해 차원을 줄이는 차원축소 알고리즘이다. 여기서 '이웃'은 주어진 포인트에서 가장 가까운 포인트 집합을 말한다. 알고리즘이 고차원에서 떨어져 있는 포인트 사이의 거리를 유지하는 것과 반대로 저차원에서 유사한 포인트를 함께 유지하는 것을 강조한다.\n",
    "\n",
    "알고리즘은 해당 고차원과 저차원공간에서 데이터 포인트의 유사성 확률 계산으로 시작된다. 포인트의 유사성은 A를 중심으로 한 정규분포에서 이웃이 확률 밀도에 비례하여 선택되면 점 A가 점 B를 이웃으로 선택할 조번주 확률로 계산한다. 그런 다음 알고리즘은 저차원 공간에 있는 데이터 포인트를 완벽히 표현하기 위해 저차원 고차원 공간에서 조건부 확률간의 차이를 최소화 한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
